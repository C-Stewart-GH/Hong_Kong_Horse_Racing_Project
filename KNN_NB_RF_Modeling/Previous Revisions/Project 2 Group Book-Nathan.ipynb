{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nathan Deinlein <br>\n",
    "Ryan Kinney <br>\n",
    "Chris Roche <br>\n",
    "Cameron Stewart <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Lab 2 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about data prep here.\n",
    "\n",
    "[10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_no</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>result</th>\n",
       "      <th>won</th>\n",
       "      <th>lengths_behind</th>\n",
       "      <th>horse_age</th>\n",
       "      <th>horse_country</th>\n",
       "      <th>horse_type</th>\n",
       "      <th>...</th>\n",
       "      <th>behind_sec2</th>\n",
       "      <th>behind_sec3</th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>place_odds</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>jockey_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3917</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>13.85</td>\n",
       "      <td>21.59</td>\n",
       "      <td>23.86</td>\n",
       "      <td>83.92</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2157</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>14.57</td>\n",
       "      <td>21.99</td>\n",
       "      <td>23.30</td>\n",
       "      <td>83.56</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>164</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.69</td>\n",
       "      <td>21.59</td>\n",
       "      <td>23.90</td>\n",
       "      <td>83.40</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>137</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1853</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3</td>\n",
       "      <td>SAF</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>14.09</td>\n",
       "      <td>21.83</td>\n",
       "      <td>23.70</td>\n",
       "      <td>83.62</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>80</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2796</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3</td>\n",
       "      <td>GB</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>8.75</td>\n",
       "      <td>4.25</td>\n",
       "      <td>14.77</td>\n",
       "      <td>21.75</td>\n",
       "      <td>23.22</td>\n",
       "      <td>83.24</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  race_id  horse_no  horse_id  result  won  lengths_behind  \\\n",
       "0           0        0         1      3917      10  0.0            8.00   \n",
       "1           1        0         2      2157       8  0.0            5.75   \n",
       "2           2        0         3       858       7  0.0            4.75   \n",
       "3           3        0         4      1853       9  0.0            6.25   \n",
       "4           4        0         5      2796       6  0.0            3.75   \n",
       "\n",
       "   horse_age horse_country horse_type  ...  behind_sec2 behind_sec3  time1  \\\n",
       "0          3           AUS    Gelding  ...         2.00        1.50  13.85   \n",
       "1          3            NZ    Gelding  ...         9.00        5.00  14.57   \n",
       "2          3            NZ    Gelding  ...         1.00        0.75  13.69   \n",
       "3          3           SAF    Gelding  ...         5.00        3.50  14.09   \n",
       "4          3            GB    Gelding  ...         8.75        4.25  14.77   \n",
       "\n",
       "   time2  time3  finish_time  win_odds  place_odds  trainer_id  jockey_id  \n",
       "0  21.59  23.86        83.92       9.7         3.7         118          2  \n",
       "1  21.99  23.30        83.56      16.0         4.9         164         57  \n",
       "2  21.59  23.90        83.40       3.5         1.5         137         18  \n",
       "3  21.83  23.70        83.62      39.0        11.0          80         59  \n",
       "4  21.75  23.22        83.24      50.0        14.0           9        154  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "url = \"https://raw.githubusercontent.com/nedeinlein/Machine_Learning_I/main/runs_clean.csv\"\n",
    "runs_df = pd.read_csv(url, index_col=False)\n",
    "\n",
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one hot encoding on non-numerical features\n",
    "## (Then remove them from the drop code chunk below)\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "tmp_df = pd.get_dummies(runs_df.horse_country,prefix='horse_country')\n",
    "runs_df_onehot = pd.concat((runs_df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(runs_df.horse_type,prefix='horse_type')\n",
    "runs_df_onehot = pd.concat((runs_df_onehot,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "runs_df = runs_df_onehot.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5 points] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro paragraph for section 2 here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "Our primary metric for evaluating model performance is Area Under the Curve (AUC). AUC score provides a good balance between accuracy, specificity, and sensitivity. In an unbalanced data set such as this one, you cannot rely on accuracy alone. \n",
    "\n",
    "Since 92% of the observations in the data set are losers, creating a \"model\" that predicts a loss for every observation would have an accuracy of 92% but offer no practical use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate.\n",
    "\n",
    "For dividing our test and train data sets we used 10-fold Stratified Cross Validation (CV). In 10-fold CV, the data set is divided into 10 groups where one becomes the hold out (test) set and the other 9 become the training data. In Stratified CV, the proportion of observations is preserved in each fold. There are many more losers than winners in this data set. Therefore, preserving the proportion of winners to losers in each fold is important to ensure you do not accidentally create a test set of all losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_no</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>result</th>\n",
       "      <th>won</th>\n",
       "      <th>lengths_behind</th>\n",
       "      <th>horse_age</th>\n",
       "      <th>horse_country</th>\n",
       "      <th>horse_type</th>\n",
       "      <th>...</th>\n",
       "      <th>horse_type_Brown</th>\n",
       "      <th>horse_type_Colt</th>\n",
       "      <th>horse_type_Filly</th>\n",
       "      <th>horse_type_Gelding</th>\n",
       "      <th>horse_type_Grey</th>\n",
       "      <th>horse_type_Horse</th>\n",
       "      <th>horse_type_Mare</th>\n",
       "      <th>horse_type_Rig</th>\n",
       "      <th>horse_type_Roan</th>\n",
       "      <th>show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3917</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2157</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1853</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3</td>\n",
       "      <td>SAF</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2796</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3</td>\n",
       "      <td>GB</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3296</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>911</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2170</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1730</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2998</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.00</td>\n",
       "      <td>3</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Mare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  race_id  horse_no  horse_id  result  won  lengths_behind  \\\n",
       "0           0        0         1      3917      10  0.0            8.00   \n",
       "1           1        0         2      2157       8  0.0            5.75   \n",
       "2           2        0         3       858       7  0.0            4.75   \n",
       "3           3        0         4      1853       9  0.0            6.25   \n",
       "4           4        0         5      2796       6  0.0            3.75   \n",
       "5           5        0         6      3296       3  0.0            1.25   \n",
       "6           6        0         7       911      12  0.0            9.50   \n",
       "7           7        0         8      2170       1  1.0            0.00   \n",
       "8           8        0         9      1730      13  0.0            9.75   \n",
       "9           9        0        10      2998      14  0.0          999.00   \n",
       "\n",
       "   horse_age horse_country horse_type  ...  horse_type_Brown horse_type_Colt  \\\n",
       "0          3           AUS    Gelding  ...                 0               0   \n",
       "1          3            NZ    Gelding  ...                 0               0   \n",
       "2          3            NZ    Gelding  ...                 0               0   \n",
       "3          3           SAF    Gelding  ...                 0               0   \n",
       "4          3            GB    Gelding  ...                 0               0   \n",
       "5          3            NZ    Gelding  ...                 0               0   \n",
       "6          3            NZ    Gelding  ...                 0               0   \n",
       "7          3           AUS    Gelding  ...                 0               0   \n",
       "8          3            NZ    Gelding  ...                 0               0   \n",
       "9          3           AUS       Mare  ...                 0               0   \n",
       "\n",
       "   horse_type_Filly  horse_type_Gelding  horse_type_Grey  horse_type_Horse  \\\n",
       "0                 0                   1                0                 0   \n",
       "1                 0                   1                0                 0   \n",
       "2                 0                   1                0                 0   \n",
       "3                 0                   1                0                 0   \n",
       "4                 0                   1                0                 0   \n",
       "5                 0                   1                0                 0   \n",
       "6                 0                   1                0                 0   \n",
       "7                 0                   1                0                 0   \n",
       "8                 0                   1                0                 0   \n",
       "9                 0                   0                0                 0   \n",
       "\n",
       "   horse_type_Mare  horse_type_Rig  horse_type_Roan  show  \n",
       "0                0               0                0     0  \n",
       "1                0               0                0     0  \n",
       "2                0               0                0     0  \n",
       "3                0               0                0     0  \n",
       "4                0               0                0     0  \n",
       "5                0               0                0     1  \n",
       "6                0               0                0     0  \n",
       "7                0               0                0     1  \n",
       "8                0               0                0     0  \n",
       "9                1               0                0     0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a Show result feature\n",
    "runs_df['show'] = np.where(runs_df['result'] <= 3, 1, 0)\n",
    "runs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horse_no</th>\n",
       "      <th>horse_age</th>\n",
       "      <th>horse_rating</th>\n",
       "      <th>declared_weight</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>place_odds</th>\n",
       "      <th>horse_country_ARG</th>\n",
       "      <th>horse_country_AUS</th>\n",
       "      <th>...</th>\n",
       "      <th>horse_country_ZIM</th>\n",
       "      <th>horse_type_Brown</th>\n",
       "      <th>horse_type_Colt</th>\n",
       "      <th>horse_type_Filly</th>\n",
       "      <th>horse_type_Gelding</th>\n",
       "      <th>horse_type_Grey</th>\n",
       "      <th>horse_type_Horse</th>\n",
       "      <th>horse_type_Mare</th>\n",
       "      <th>horse_type_Rig</th>\n",
       "      <th>horse_type_Roan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>133</td>\n",
       "      <td>7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>980.0</td>\n",
       "      <td>133</td>\n",
       "      <td>12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>132</td>\n",
       "      <td>8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>127</td>\n",
       "      <td>13</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>972.0</td>\n",
       "      <td>131</td>\n",
       "      <td>14</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   horse_no  horse_age  horse_rating  declared_weight  actual_weight  draw  \\\n",
       "0         1          3            60           1020.0            133     7   \n",
       "1         2          3            60            980.0            133    12   \n",
       "2         3          3            60           1082.0            132     8   \n",
       "3         4          3            60           1118.0            127    13   \n",
       "4         5          3            60            972.0            131    14   \n",
       "\n",
       "   win_odds  place_odds  horse_country_ARG  horse_country_AUS  ...  \\\n",
       "0       9.7         3.7                  0                  1  ...   \n",
       "1      16.0         4.9                  0                  0  ...   \n",
       "2       3.5         1.5                  0                  0  ...   \n",
       "3      39.0        11.0                  0                  0  ...   \n",
       "4      50.0        14.0                  0                  0  ...   \n",
       "\n",
       "   horse_country_ZIM  horse_type_Brown  horse_type_Colt  horse_type_Filly  \\\n",
       "0                  0                 0                0                 0   \n",
       "1                  0                 0                0                 0   \n",
       "2                  0                 0                0                 0   \n",
       "3                  0                 0                0                 0   \n",
       "4                  0                 0                0                 0   \n",
       "\n",
       "   horse_type_Gelding  horse_type_Grey  horse_type_Horse  horse_type_Mare  \\\n",
       "0                   1                0                 0                0   \n",
       "1                   1                0                 0                0   \n",
       "2                   1                0                 0                0   \n",
       "3                   1                0                 0                0   \n",
       "4                   1                0                 0                0   \n",
       "\n",
       "   horse_type_Rig  horse_type_Roan  \n",
       "0               0                0  \n",
       "1               0                0  \n",
       "2               0                0  \n",
       "3               0                0  \n",
       "4               0                0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_data = runs_df.drop(['Unnamed: 0','race_id','horse_id','result','won','lengths_behind','horse_country','horse_type','horse_gear','position_sec1','position_sec2','position_sec3','behind_sec1','behind_sec2','behind_sec3','time1','time2','time3','finish_time','trainer_id','jockey_id','show'], axis=1)\n",
    "runs_target = runs_df['won']\n",
    "runs_target2 = runs_df['show']\n",
    "runs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split won\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(runs_data,runs_target,test_size=0.20,random_state=0)\n",
    "mmscl_obj = MinMaxScaler()\n",
    "X_train = mmscl_obj.fit_transform(X_train,y = None)\n",
    "X_test = mmscl_obj.transform(X_test)\n",
    "\n",
    "#train test split place\n",
    "X_train_place,X_test_place,Y_train_place,Y_test_place = train_test_split(runs_data,runs_target2,test_size=0.20,random_state=0)\n",
    "mmscl_obj = MinMaxScaler()\n",
    "X_train_place = mmscl_obj.fit_transform(X_train_place,y = None)\n",
    "X_test_place = mmscl_obj.transform(X_test_place)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1: Model 1 - K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors is an algorithm frequently used for classification. In order to classify an observation, the algorithm measures the distance from the given observation to it's K nearest neighbors, where K is a tunable parameter.\n",
    "\n",
    "For each iteration of the model fitting, we try a different K value and print out the model accuracy and AUC score. Because the data set is not balanced, we use AUC as the primary metric for comparing model performance. If we only used accuracy, we could achieve an accuracy of over 90% simply by classifying every observation as a \"los\", but this has no practical use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we implemented two models. Both use Euclidean distance but one uses a uniform weight and the other uses distance. For uniform weight, all the nearest neighbors have the same impact in classification. In distance, closer neighbors have more impact.\n",
    "\n",
    "The difference in model performance for uniform vs. distance was negligable, but the model with weights='distance' trained more quickly so we elected to use that parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance, Uniform Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Euclidean distance and iterate over several K-values\n",
    "## â€˜uniformâ€™ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='uniform', metric='euclidean')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance, Distance Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Euclidean distance - sqrt(sum((x - y)^2))\n",
    "## â€˜distanceâ€™ : weight points by the inverse of their distance. \n",
    "##    in this case, closer neighbors of a query point will have a greater \n",
    "##    influence than neighbors which are further away.\n",
    "\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='euclidean')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)\n",
    "    \n",
    "# Note: weights='distance' runs quicker and produces the same accuracy results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next parameter we experimented with was the weight metric. We re-ran the model several times using different metrics from the sklearn DistanceMetric library, to include Manhatten and Chebyshev.\n",
    "\n",
    "Again, the model performance for the different metrics was negligable so we elected to use Euclidean distance since it is well optimized for large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhatten Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Manhatten distance - sum(|x - y|)\n",
    "\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='manhattan')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ChebyshevDistance distance - max(|x - y|)\n",
    "\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='chebyshev')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each of the KNN models above, the accuracy and AUC tend to stabilize at around k=11. Note as the K value increases so too does the accuracy but the AUC decreases. Choosing a smaller K-value such as 7 produces a goo balace between the different metrics.\n",
    "\n",
    "We fit a final KNN using the parameters selected: Euclidean, Distance weights for neighbors, and 7 neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN with Euclidean, Distance weight, and K=7 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on above, Euclidean with K=7 is a good combination of accuracy and AUC\n",
    "x=7\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='euclidean')\n",
    "clf_knn.fit(X_train,Y_train)\n",
    "yhat= clf_knn.predict(X_test)\n",
    "acc = mt.accuracy_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)\n",
    "conf = mt.confusion_matrix(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Confusion Matrix plotted for the model. As can be seen, it classified the majority of observations as loses (correctly). This makes sense since about 92% of the data set are horses who did not win their race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_knn, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried several different algorithm parameters here (e.g. kd_tree, ball_tree) without effect\n",
    "x=7\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='euclidean', algorithm='kd_tree')\n",
    "clf_knn.fit(X_train,Y_train)\n",
    "yhat= clf_knn.predict(X_test)\n",
    "acc = mt.accuracy_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)\n",
    "conf = mt.confusion_matrix(Y_test,yhat)\n",
    "print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Confusion Matrix above, notice the large number of false positives. The model incorrectly classified over 1000 observations as wins when they should have been loses. It only correctly classified about 50 wins. Since this data set is results of horse races, you can assume an interested party would be a gambler. The KNN model would not be of much benefit to a gambler due to the large number of Type I error in proportion to true positive results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2: Model 2 - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "The first parameter we want to look at is the performance of forest size to find an optimal number of trees based on the initial data. Determining the correct size of the forest can help keep us from overfitting the model or by wasting resources with building an unneccessarily large forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [64,75,100,128]\n",
    "for x in trees:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = 5, n_estimators = x, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedKFold(n_splits = 10, shuffle = True ,random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, runs_data, runs_target, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Trees =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this information we are aiming for the best precision in our models as we want the best possible number of positive results while limiting false positives. So from this we would look at building a forest with 64 trees. This is also nice because it is the least time consuming. Next we will use this to run a loop to fine the optimal max_depth. This is the metric that determines the overall size of each individual tree by limiting the number of levels it can break down the data into. We will be looking at four levels in this loop, 5,20,100, and no limit(none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [5,20,100,None]\n",
    "for x in depth:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = x, n_estimators = 64, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, runs_data, runs_target, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Depth =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After assessing these results we wanted to take a look at feature importance on the selected model above. The reason for this is we want to try to eliminate noise variables. This has a secondary side effect with random forests of letting them run faster since the number of features is reduces. There were two ways we went about doing this for random forest. The first was a manual look at the feature importance, and selecting what we deemed to be the most important. The second way was to use recursive feature elimination with cross-validation to look at removing variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run best model with normal train test split for feature selection\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "# fill in the training and testing data and save as separate variables\n",
    "for trainidx, testidx in cv.split(runs_data,runs_target):\n",
    "    # note that these are sparse matrices\n",
    "    X_train, X_test = runs_data.iloc[trainidx], runs_data.iloc[testidx] \n",
    "    Y_train, Y_test = runs_target.iloc[trainidx], runs_target.iloc[testidx]\n",
    "\n",
    "mmscl_obj = MinMaxScaler()\n",
    "X_train = mmscl_obj.fit_transform(X_train,y = None)\n",
    "X_test = mmscl_obj.transform(X_test)\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth = 100, n_estimators = 64, random_state = 0, class_weight = 'balanced')\n",
    "clf_rf.fit(X_train,Y_train.values.ravel())\n",
    "yhat = clf_rf.predict(X_test)\n",
    "prec = mt.precision_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(runs_data.columns.values)\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "imps = permutation_importance(clf_rf, X_test, Y_test)\n",
    "importances = imps.importances_mean\n",
    "std = imps.importances_std\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "\n",
    "featureorder = []\n",
    "for f in range(X_test.shape[1]):\n",
    "    featureorder.append(features[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_test.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_test.shape[1]), [features[indices[i]] for i in range(33)],rotation = 90)\n",
    "plt.xlim([-1, X_test.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by looking at this graph we can make some simple eliminations of features that did not help in this model. Likely we would want to keep the first three factors and the last 15 factors in the model and eliminate the rest. This has been done in the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optfeatures = featureorder[:3]\n",
    "optfeatures2 = featureorder[-15:]\n",
    "optfeatures = optfeatures + optfeatures2\n",
    "dataopt = runs_data[optfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "rfecv = RFECV(estimator=clf_rf, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='precision',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (precision)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()\n",
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfecv.support_[i], rfecv.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping features from dataset not selected by recursive feature elimination\n",
    "dataopt2 = runs_data.drop(runs_data.columns[[10,15,21,26,28,32]],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building out these new datasets we decided to run the same crossvalidated pieces against them. You can see the results of these below. The first two loops are run on the manually optimized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [64,75,100,128]\n",
    "for x in trees:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = 5, n_estimators = x, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, dataopt, runs_target, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Trees =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the set of manually optimized data we see that 75 trees has the greatest precision. We are also seeing increased scores for AUC and Precision. There is a jump here from .7794 to .782 and .1734 to .1751 respectively. The model, however, does take slightly longer to run with the larger forest size, but not substantially longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [5,20,100,None]\n",
    "for x in depth:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = x, n_estimators = 75, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, dataopt, runs_target, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Depth =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results from max_depth, we would want to select a depth max of 100 like in the last model. This is because the difference between precision and AUC is none existant between limiting depth to 100 and no limit. So the runtime benefit here is the deciding factor. Next we will run this again but with the recursive feature elimination dataset to see if there is a difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [64,75,100,128]\n",
    "for x in trees:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = 5, n_estimators = x, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, dataopt2, runs_target, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Trees =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just based on this first run. It doesnt look like the recursive feature elimination will beat out the manual feature selection but for the sake of being thorough we went ahead and ran the loop to look at depth with a forest size of 128 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [5,20,100,None]\n",
    "for x in depth:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = x, n_estimators = 75, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, dataopt2, runs_target, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Depth =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this loop were surprising as originally it looked as though the RFE dataset would be coming back with lower stats than the manually selected features. However, once the loop for max depth was run there was a jump in statistics from precision .4219 and AUC .7477 to precision .4277 and AUC .7491 at a max depth of 100. This means that our best model for runtime efficiency, precision and AUC would be a Random Forest with weight classed balance, a max depth of 100 and forest size of 75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "Now that we have a best model for the wins of task one we need to move to task two of trying to classify horses that place instead of just the winners from each race. In theory the statistics for these models should all be better due to the fact that the number of posible successes is higher proportionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [5,20,100,None]\n",
    "for x in depth:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = x, n_estimators = 64, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, runs_data, runs_target2, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Depth =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first run of the data running a with no max depth interestingly seems to be comparable statistics wise with running a model with max depth 100, and strangly it ran faster than the max depth 100. So we will now run the loop again to tune forest size using this max depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [64,75,100,128]\n",
    "for x in trees:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = None, n_estimators = x, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, runs_data, runs_target2, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Trees =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the second loop our best metrics can be found with a forest size of 128 trees. Now that we have these base statistics. We will want to again optimize the data set using RFE. We decided not to attempt to beat the machine this time and instead utilize RFE to expidite model build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run best model with normal train test split for feature selection\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "# fill in the training and testing data and save as separate variables\n",
    "for trainidx, testidx in cv.split(runs_data,runs_target2):\n",
    "    # note that these are sparse matrices\n",
    "    X_train, X_test = runs_data.iloc[trainidx], runs_data.iloc[testidx] \n",
    "    Y_train, Y_test = runs_target.iloc[trainidx], runs_target.iloc[testidx]\n",
    "\n",
    "mmscl_obj = MinMaxScaler()\n",
    "X_train = mmscl_obj.fit_transform(X_train,y = None)\n",
    "X_test = mmscl_obj.transform(X_test)\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth = None, n_estimators = 128, random_state = 0, class_weight = 'balanced')\n",
    "clf_rf.fit(X_train,Y_train.values.ravel())\n",
    "yhat = clf_rf.predict(X_test)\n",
    "prec = mt.precision_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "rfecv = RFECV(estimator=clf_rf, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='precision',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (precision)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()\n",
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfecv.support_[i], rfecv.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping features from dataset not selected by recursive feature elimination\n",
    "dataopt3 = runs_data.drop(runs_data.columns[[8,10,11,14,15,17,18,20,21,23,25,26,28,30,31,32]],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data set because the number of possible successes goes up, it is not surprising that a smaller number of features is needed to predict this success. We see all the same features eliminated that were eliminated when predicting a winner, but more are added to the list as they are less important in predicting a top 3 placing. Now that we have the optimized dataset for place. We will run the loops again to look for improved performace of both metrics and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [5,20,100,None]\n",
    "for x in depth:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = x, n_estimators = 64, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, dataopt2, runs_target2, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Depth =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting looking at this data where the depth 5 statistics beat the original non-optimized model, however as depth increased. The optimized model didnt seem to keep pace with the original model.  This might be a similar situation to the last attempt at optimization though where the final model did manage to beat out the original model. From this we will use max depth None to try to optimize our final model. The reason for chosing None of 100 even though 100 had a better calculation speed was to try to compare like for like models here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [64,75,100,128]\n",
    "for x in trees:\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', RandomForestClassifier(max_depth = None, n_estimators = x, random_state = 0, class_weight = 'balanced')))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # define the evaluation procedure\n",
    "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "    #Modeling with pipeline and scoring with cross_validate()\n",
    "    scores = cross_validate(pipeline, dataopt2, runs_target2, scoring=['roc_auc','accuracy','precision'],\n",
    "                             cv=cv, return_train_score=False)\n",
    "    print('When Trees =',x)\n",
    "    print('   Mean Precision: ',np.mean(scores['test_precision']))\n",
    "    print('   Mean AUC: ',np.mean(scores['test_roc_auc']))\n",
    "    print('   Mean Accuracy: ',np.mean(scores['test_accuracy']))\n",
    "    print('   Mean Time per Split: ',np.mean(scores['fit_time'])+np.mean(scores['score_time']))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final optimized model would have been with a max_depth of None and a forest size of x. Interestingly the optimized model here did not perform better than the full model. This could be because the algorithm for it is trying to balance bias and variability and this time the metrics just didn't increase the precision, but may have made it more adaptable to another data set. However, just based on metrics alone, the full model should be deployed in this case. To compare these to the other types of models we are going to use AUC as it is an easy statistical measure of the predictive power of each model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3: Model 3 - Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement model here, including accuracy, AUC score, and Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4: Model 4 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement model here, including accuracy, AUC score, and Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first type of Naive Bayes we would like to run is the Gaussian Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR: 0.25 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 0.5 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 1 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 2 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 3 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 4 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 5 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 6 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 7 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 8 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 9 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 10 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 15 AUC: 0.5 ACC: 0.9207428391564368\n",
      "VAR: 20 AUC: 0.5 ACC: 0.9207428391564368\n"
     ]
    }
   ],
   "source": [
    "var = [.25,.5,1,2,3,4,5,6,7,8,9,10,15,20]\n",
    "for x in var:\n",
    "    clf_gnb = GaussianNB(var_smoothing = x)\n",
    "    clf_gnb.fit(X_train,Y_train.values.ravel())\n",
    "    yhat = clf_gnb.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('VAR:',x,'AUC:',auc,'ACC:',acc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Var smoothing at 1 provided the best result below is out test model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR:1 AUC: 0.5 ACC: 0.9207428391564368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nedei\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x231070ab130>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_gnb = GaussianNB(var_smoothing = 1)\n",
    "clf_gnb.fit(X_train,Y_train.values.ravel())\n",
    "yhat = clf_gnb.predict(X_test)\n",
    "acc = mt.accuracy_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)\n",
    "conf = mt.confusion_matrix(Y_test,yhat)\n",
    "print('VAR:1 AUC:',auc,'ACC:',acc)\n",
    "plot_confusion_matrix(clf_gnb,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will want to look at the feature importance of the model to see if there are any features that could be left out to try to remove noise from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = list(runs_data.columns.values)\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "imps = permutation_importance(clf_gnb, X_test, Y_test)\n",
    "importances = imps.importances_mean\n",
    "std = imps.importances_std\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "\n",
    "featureorder = []\n",
    "for f in range(X_test.shape[1]):\n",
    "    featureorder.append(features[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_test.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_test.shape[1]), [features[indices[i]] for i in range(33)],rotation = 90)\n",
    "plt.xlim([-1, X_test.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model we want to look at is a Complement Naive Bayes. Due to how Complement Naive Bayes works, it has to be scaled differently as it cannot handle negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.25 AUC: 0.6869380972486375 ACC: 0.561347182876928\n",
      "Alpha: 0.5 AUC: 0.6855026346403887 ACC: 0.561347182876928\n",
      "Alpha: 1 AUC: 0.6866309592518423 ACC: 0.5621026125275417\n",
      "Alpha: 2 AUC: 0.6878285230648854 ACC: 0.5643059490084986\n",
      "Alpha: 3 AUC: 0.6893507364210467 ACC: 0.566446333018571\n",
      "Alpha: 4 AUC: 0.6910440303219285 ACC: 0.5689014793830658\n",
      "Alpha: 5 AUC: 0.6917283525008102 ACC: 0.5701605288007554\n",
      "Alpha: 6 AUC: 0.6936444546016793 ACC: 0.5736858671702865\n",
      "Alpha: 7 AUC: 0.6945173688716044 ACC: 0.5759521561221278\n",
      "Alpha: 8 AUC: 0.6950314174894672 ACC: 0.5782184450739691\n",
      "Alpha: 9 AUC: 0.69554546610733 ACC: 0.5804847340258105\n",
      "Alpha: 10 AUC: 0.6952391350942363 ACC: 0.5825621655649984\n",
      "Alpha: 15 AUC: 0.7010933176584819 ACC: 0.5986150456405414\n",
      "Alpha: 20 AUC: 0.7020610525133346 ACC: 0.6162417374881964\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "# fill in the training and testing data and save as separate variables\n",
    "for trainidx, testidx in cv.split(runs_data,runs_target):\n",
    "    # note that these are sparse matrices\n",
    "    cnbX_train, cnbX_test = runs_data.iloc[trainidx], runs_data.iloc[testidx] \n",
    "    cnbY_train, cnbY_test = runs_target.iloc[trainidx], runs_target.iloc[testidx]\n",
    "\n",
    "mmscl_obj = MinMaxScaler()\n",
    "cnbX_train = mmscl_obj.fit_transform(cnbX_train,y = None)\n",
    "cnbX_test = mmscl_obj.fit_transform(cnbX_test,y = None)\n",
    "\n",
    "for x in var:\n",
    "    clf_cnb = ComplementNB(alpha = x)\n",
    "    clf_cnb.fit(cnbX_train,cnbY_train.values.ravel())\n",
    "    yhat = clf_cnb.predict(cnbX_test)\n",
    "    acc = mt.accuracy_score(cnbY_test,yhat)\n",
    "    auc = roc_auc_score(cnbY_test,yhat)\n",
    "    print('Alpha:',x,'AUC:',auc,'ACC:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnb = ComplementNB(alpha = 20)\n",
    "clf_cnb.fit(cnbX_train,cnbY_train.values.ravel())\n",
    "yhat = clf_cnb.predict(cnbX_test)\n",
    "acc = mt.accuracy_score(cnbY_test,yhat)\n",
    "auc = roc_auc_score(cnbY_test,yhat)\n",
    "print('Alpha:20 AUC:',auc,'ACC:',acc)\n",
    "plot_confusion_matrix(clf_cnb,cnbX_test,cnbY_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(runs_data.columns.values)\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "imps = permutation_importance(clf_cnb, cnbX_test, cnbY_test)\n",
    "importances = imps.importances_mean\n",
    "std = imps.importances_std\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "\n",
    "featureorder = []\n",
    "for f in range(cnbX_test.shape[1]):\n",
    "    featureorder.append(features[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(cnbX_test.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(cnbX_test.shape[1]), [features[indices[i]] for i in range(33)],rotation = 90)\n",
    "plt.xlim([-1, cnbX_test.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final type we would like to try is Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in var:\n",
    "    clf_bnb = BernoulliNB(alpha = x)\n",
    "    clf_bnb.fit(X_train,Y_train.values.ravel())\n",
    "    yhat = clf_bnb.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Alpha:',x,'AUC:',auc,'ACC:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bnb = BernoulliNB(alpha = 1)\n",
    "clf_bnb.fit(X_train,Y_train.values.ravel())\n",
    "yhat = clf_bnb.predict(X_test)\n",
    "acc = mt.accuracy_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)\n",
    "conf = mt.confusion_matrix(Y_test,yhat)\n",
    "print('Alpha:',x,'AUC:',auc,'ACC:',acc)\n",
    "plot_confusion_matrix(clf_bnb,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtendNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from mlxtend) (1.18.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from mlxtend) (49.2.0.post20200714)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from mlxtend) (3.2.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from mlxtend) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from mlxtend) (1.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nedei\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.19.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5: Model Comparison and Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods.\n",
    "\n",
    "[10 points] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5 points] How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the Lab here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
