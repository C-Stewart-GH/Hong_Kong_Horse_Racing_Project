{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nathan Deinlein <br>\n",
    "Ryan Kinney <br>\n",
    "Chris Roche <br>\n",
    "Cameron Stewart <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Lab 2 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about data prep here.\n",
    "\n",
    "[10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_no</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>result</th>\n",
       "      <th>won</th>\n",
       "      <th>lengths_behind</th>\n",
       "      <th>horse_age</th>\n",
       "      <th>horse_country</th>\n",
       "      <th>horse_type</th>\n",
       "      <th>...</th>\n",
       "      <th>behind_sec2</th>\n",
       "      <th>behind_sec3</th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>place_odds</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>jockey_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3917</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>13.85</td>\n",
       "      <td>21.59</td>\n",
       "      <td>23.86</td>\n",
       "      <td>83.92</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2157</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>14.57</td>\n",
       "      <td>21.99</td>\n",
       "      <td>23.30</td>\n",
       "      <td>83.56</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>164</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.69</td>\n",
       "      <td>21.59</td>\n",
       "      <td>23.90</td>\n",
       "      <td>83.40</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>137</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1853</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3</td>\n",
       "      <td>SAF</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>14.09</td>\n",
       "      <td>21.83</td>\n",
       "      <td>23.70</td>\n",
       "      <td>83.62</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>80</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2796</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3</td>\n",
       "      <td>GB</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>...</td>\n",
       "      <td>8.75</td>\n",
       "      <td>4.25</td>\n",
       "      <td>14.77</td>\n",
       "      <td>21.75</td>\n",
       "      <td>23.22</td>\n",
       "      <td>83.24</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  race_id  horse_no  horse_id  result  won  lengths_behind  \\\n",
       "0           0        0         1      3917      10  0.0            8.00   \n",
       "1           1        0         2      2157       8  0.0            5.75   \n",
       "2           2        0         3       858       7  0.0            4.75   \n",
       "3           3        0         4      1853       9  0.0            6.25   \n",
       "4           4        0         5      2796       6  0.0            3.75   \n",
       "\n",
       "   horse_age horse_country horse_type  ...  behind_sec2 behind_sec3  time1  \\\n",
       "0          3           AUS    Gelding  ...         2.00        1.50  13.85   \n",
       "1          3            NZ    Gelding  ...         9.00        5.00  14.57   \n",
       "2          3            NZ    Gelding  ...         1.00        0.75  13.69   \n",
       "3          3           SAF    Gelding  ...         5.00        3.50  14.09   \n",
       "4          3            GB    Gelding  ...         8.75        4.25  14.77   \n",
       "\n",
       "   time2  time3  finish_time  win_odds  place_odds  trainer_id  jockey_id  \n",
       "0  21.59  23.86        83.92       9.7         3.7         118          2  \n",
       "1  21.99  23.30        83.56      16.0         4.9         164         57  \n",
       "2  21.59  23.90        83.40       3.5         1.5         137         18  \n",
       "3  21.83  23.70        83.62      39.0        11.0          80         59  \n",
       "4  21.75  23.22        83.24      50.0        14.0           9        154  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "url = \"https://raw.githubusercontent.com/nedeinlein/Machine_Learning_I/main/runs_clean.csv\"\n",
    "runs_df = pd.read_csv(url, index_col=False)\n",
    "\n",
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one hot encoding on non-numerical features\n",
    "## (Then remove them from the drop code chunk below)\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "tmp_df = pd.get_dummies(runs_df.horse_country,prefix='horse_country')\n",
    "runs_df_onehot = pd.concat((runs_df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(runs_df.horse_type,prefix='horse_type')\n",
    "runs_df_onehot = pd.concat((runs_df_onehot,tmp_df),axis=1) # add back into the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5 points] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro paragraph for section 2 here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "Our primary metric for evaluating model performance is Area Under the Curve (AUC). AUC score provides a good balance between accuracy, specificity, and sensitivity. In an unbalanced data set such as this one, you cannot rely on accuracy alone. \n",
    "\n",
    "Since 92% of the observations in the data set are losers, creating a \"model\" that predicts a loss for every observation would have an accuracy of 92% but offer no practical use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate.\n",
    "\n",
    "For dividing our test and train data sets we used 10-fold Stratified Cross Validation (CV). In 10-fold CV, the data set is divided into 10 groups where one becomes the hold out (test) set and the other 9 become the training data. In Stratified CV, the proportion of observations is preserved in each fold. There are many more losers than winners in this data set. Therefore, preserving the proportion of winners to losers in each fold is important to ensure you do not accidentally create a test set of all losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horse_no</th>\n",
       "      <th>horse_age</th>\n",
       "      <th>horse_rating</th>\n",
       "      <th>declared_weight</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>place_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>133</td>\n",
       "      <td>7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>980.0</td>\n",
       "      <td>133</td>\n",
       "      <td>12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>132</td>\n",
       "      <td>8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>127</td>\n",
       "      <td>13</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>972.0</td>\n",
       "      <td>131</td>\n",
       "      <td>14</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   horse_no  horse_age  horse_rating  declared_weight  actual_weight  draw  \\\n",
       "0         1          3            60           1020.0            133     7   \n",
       "1         2          3            60            980.0            133    12   \n",
       "2         3          3            60           1082.0            132     8   \n",
       "3         4          3            60           1118.0            127    13   \n",
       "4         5          3            60            972.0            131    14   \n",
       "\n",
       "   win_odds  place_odds  \n",
       "0       9.7         3.7  \n",
       "1      16.0         4.9  \n",
       "2       3.5         1.5  \n",
       "3      39.0        11.0  \n",
       "4      50.0        14.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df = runs_df.reset_index(drop=True)\n",
    "runs_data = runs_df.drop(['Unnamed: 0','race_id','horse_id','result','won','lengths_behind','horse_country','horse_type','horse_gear','position_sec1','position_sec2','position_sec3','behind_sec1','behind_sec2','behind_sec3','time1','time2','time3','finish_time','trainer_id','jockey_id'], axis=1)\n",
    "runs_target = runs_df['won']\n",
    "runs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.2, train_size=0.8, random_state = 0)\n",
    "\n",
    "# fill in the training and testing data and save as separate variables\n",
    "for trainidx, testidx in cv.split(runs_data,runs_target):\n",
    "    # note that these are sparse matrices\n",
    "    X_train,X_test = runs_data.iloc[trainidx], runs_data.iloc[testidx] \n",
    "    Y_train, Y_test = runs_target.iloc[trainidx], runs_target.iloc[testidx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl_obj = StandardScaler()\n",
    "X_train = scl_obj.fit_transform(X_train, y = None)\n",
    "X_test = scl_obj.fit_transform(X_test, y = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1: Model 1 - K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors is an algorithm frequently used for classification. In order to classify an observation, the algorithm measures the distance from the given observation to it's K nearest neighbors, where K is a tunable parameter.\n",
    "\n",
    "For each iteration of the model fitting, we try a different K value and print out the model accuracy and AUC score. Because the data set is not balanced, we use AUC as the primary metric for comparing model performance. If we only used accuracy, we could achieve an accuracy of over 90% simply by classifying every observation as a \"los\", but this has no practical use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we implemented two models. Both use Euclidean distance but one uses a uniform weight and the other uses distance. For uniform weight, all the nearest neighbors have the same impact in classification. In distance, closer neighbors have more impact.\n",
    "\n",
    "The difference in model performance for uniform vs. distance was negligable, but the model with weights='distance' trained more quickly so we elected to use that parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance, Uniform Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier with 3 neighbors is: 0.900  AUC: 0.513\n",
      "Accuracy of classifier with 5 neighbors is: 0.913  AUC: 0.508\n",
      "Accuracy of classifier with 7 neighbors is: 0.917  AUC: 0.504\n",
      "Accuracy of classifier with 9 neighbors is: 0.918  AUC: 0.501\n",
      "Accuracy of classifier with 11 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 13 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 15 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 17 neighbors is: 0.920  AUC: 0.500\n",
      "Accuracy of classifier with 19 neighbors is: 0.920  AUC: 0.500\n",
      "Accuracy of classifier with 21 neighbors is: 0.920  AUC: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Use Euclidean distance and iterate over several K-values\n",
    "## ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='uniform', metric='euclidean')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance, Distance Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier with 3 neighbors is: 0.897  AUC: 0.517\n",
      "Accuracy of classifier with 5 neighbors is: 0.910  AUC: 0.511\n",
      "Accuracy of classifier with 7 neighbors is: 0.915  AUC: 0.508\n",
      "Accuracy of classifier with 9 neighbors is: 0.917  AUC: 0.504\n",
      "Accuracy of classifier with 11 neighbors is: 0.918  AUC: 0.504\n",
      "Accuracy of classifier with 13 neighbors is: 0.919  AUC: 0.502\n",
      "Accuracy of classifier with 15 neighbors is: 0.919  AUC: 0.501\n",
      "Accuracy of classifier with 17 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 19 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 21 neighbors is: 0.920  AUC: 0.501\n"
     ]
    }
   ],
   "source": [
    "# Use Euclidean distance - sqrt(sum((x - y)^2))\n",
    "## ‘distance’ : weight points by the inverse of their distance. \n",
    "##    in this case, closer neighbors of a query point will have a greater \n",
    "##    influence than neighbors which are further away.\n",
    "\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='euclidean')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)\n",
    "    \n",
    "# Note: weights='distance' runs quicker and produces the same accuracy results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next parameter we experimented with was the weight metric. We re-ran the model several times using different metrics from the sklearn DistanceMetric library, to include Manhatten and Chebyshev.\n",
    "\n",
    "Again, the model performance for the different metrics was negligable so we elected to use Euclidean distance since it is well optimized for large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhatten Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier with 3 neighbors is: 0.898  AUC: 0.520\n",
      "Accuracy of classifier with 5 neighbors is: 0.909  AUC: 0.514\n",
      "Accuracy of classifier with 7 neighbors is: 0.915  AUC: 0.511\n",
      "Accuracy of classifier with 9 neighbors is: 0.917  AUC: 0.509\n",
      "Accuracy of classifier with 11 neighbors is: 0.919  AUC: 0.505\n",
      "Accuracy of classifier with 13 neighbors is: 0.920  AUC: 0.503\n",
      "Accuracy of classifier with 15 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 17 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 19 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 21 neighbors is: 0.920  AUC: 0.501\n"
     ]
    }
   ],
   "source": [
    "# Use Manhatten distance - sum(|x - y|)\n",
    "\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='manhattan')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier with 3 neighbors is: 0.899  AUC: 0.516\n",
      "Accuracy of classifier with 5 neighbors is: 0.910  AUC: 0.507\n",
      "Accuracy of classifier with 7 neighbors is: 0.915  AUC: 0.506\n",
      "Accuracy of classifier with 9 neighbors is: 0.917  AUC: 0.503\n",
      "Accuracy of classifier with 11 neighbors is: 0.919  AUC: 0.503\n",
      "Accuracy of classifier with 13 neighbors is: 0.919  AUC: 0.501\n",
      "Accuracy of classifier with 15 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 17 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 19 neighbors is: 0.920  AUC: 0.501\n",
      "Accuracy of classifier with 21 neighbors is: 0.920  AUC: 0.501\n"
     ]
    }
   ],
   "source": [
    "# Use ChebyshevDistance distance - max(|x - y|)\n",
    "\n",
    "Kvals = [3,5,7,9,11,13,15,17,19,21]\n",
    "for x in Kvals:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='chebyshev')\n",
    "    clf_knn.fit(X_train,Y_train)\n",
    "    yhat= clf_knn.predict(X_test)\n",
    "    acc = mt.accuracy_score(Y_test,yhat)\n",
    "    auc = roc_auc_score(Y_test,yhat)\n",
    "    conf = mt.confusion_matrix(Y_test,yhat)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each of the KNN models above, the accuracy and AUC tend to stabilize at around k=11. Note as the K value increases so too does the accuracy but the AUC decreases. Choosing a smaller K-value such as 7 produces a goo balace between the different metrics.\n",
    "\n",
    "We fit a final KNN using the parameters selected: Euclidean, Distance weights for neighbors, and 7 neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN with Euclidean, Distance weight, and K=7 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on above, Euclidean with K=7 is a good combination of accuracy and AUC\n",
    "x=7\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='euclidean')\n",
    "clf_knn.fit(X_train,Y_train)\n",
    "yhat= clf_knn.predict(X_test)\n",
    "acc = mt.accuracy_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)\n",
    "conf = mt.confusion_matrix(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Confusion Matrix plotted for the model. As can be seen, it classified the majority of observations as loses (correctly). This makes sense since about 92% of the data set are horses who did not win their race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1f11580ffd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(clf_knn, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier with 7 neighbors is: 0.915  AUC: 0.508\n"
     ]
    }
   ],
   "source": [
    "# I tried several different algorithm parameters here (e.g. kd_tree, ball_tree) without effect\n",
    "x=7\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=x, weights='distance', metric='euclidean', algorithm='kd_tree')\n",
    "clf_knn.fit(X_train,Y_train)\n",
    "yhat= clf_knn.predict(X_test)\n",
    "acc = mt.accuracy_score(Y_test,yhat)\n",
    "auc = roc_auc_score(Y_test,yhat)\n",
    "conf = mt.confusion_matrix(Y_test,yhat)\n",
    "print('Accuracy of classifier with %d neighbors is: %.3f'%(x,acc), ' AUC: %.3f'%auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Confusion Matrix above, notice the large number of false positives. The model incorrectly classified over 1000 observations as wins when they should have been loses. It only correctly classified about 50 wins. Since this data set is results of horse races, you can assume an interested party would be a gambler. The KNN model would not be of much benefit to a gambler due to the large number of Type I error in proportion to true positive results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2: Model 2 - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement model here, including accuracy, AUC score, and Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3: Model 3 - Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement model here, including accuracy, AUC score, and Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4: Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement model here, including accuracy, AUC score, and Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5: Model Comparison and Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods.\n",
    "\n",
    "[10 points] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5 points] How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the Lab here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
